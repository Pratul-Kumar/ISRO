{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6438ff0d",
   "metadata": {},
   "source": [
    "# Forest Fire Prediction Model Training\n",
    "\n",
    "This notebook demonstrates the training and evaluation of fire prediction models (U-Net and LSTM) using the forest fire prediction pipeline.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Configuration\n",
    "2. Data Preprocessing\n",
    "3. Model Training (U-Net)\n",
    "4. Model Training (LSTM)\n",
    "5. Model Evaluation and Comparison\n",
    "6. Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09474a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom modules\n",
    "from utils import load_config, create_output_directories\n",
    "from data_preprocessing import FireDataPreprocessor\n",
    "from fire_prediction_model import UNetFirePredictor, LSTMFirePredictor, ModelEvaluator\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(\"Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0ed13",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = '../config/default_config.yaml'\n",
    "\n",
    "try:\n",
    "    config = load_config(config_path)\n",
    "    print(\"Configuration loaded successfully\")\n",
    "    \n",
    "    # Display key configuration parameters\n",
    "    print(\"\\nKey Configuration Parameters:\")\n",
    "    print(f\"  Model Type: {config.get('model_type', 'unet')}\")\n",
    "    print(f\"  Target Resolution: {config.get('target_resolution', 30)} meters\")\n",
    "    print(f\"  Batch Size: {config.get('batch_size', 16)}\")\n",
    "    print(f\"  Epochs: {config.get('epochs', 100)}\")\n",
    "    print(f\"  Learning Rate: {config.get('learning_rate', 0.001)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading configuration: {e}\")\n",
    "    # Create default configuration for demonstration\n",
    "    config = {\n",
    "        'model_type': 'unet',\n",
    "        'target_resolution': 30.0,\n",
    "        'batch_size': 8,\n",
    "        'epochs': 50,\n",
    "        'learning_rate': 0.001,\n",
    "        'input_shape': [256, 256, 10],\n",
    "        'paths': {\n",
    "            'outputs': '../data/outputs',\n",
    "            'models': '../models',\n",
    "            'processed_data': '../data/processed'\n",
    "        }\n",
    "    }\n",
    "    print(\"Using default configuration for demonstration\")\n",
    "\n",
    "# Create output directories\n",
    "output_dirs = create_output_directories(config['paths']['outputs'])\n",
    "config['output_dirs'] = output_dirs\n",
    "\n",
    "print(f\"\\nOutput directories created at: {config['paths']['outputs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b2b16",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_training_data(n_samples=1000, n_features=10, image_size=(64, 64)):\n",
    "    \"\"\"Generate sample data for model training demonstration.\"\"\"\n",
    "    \n",
    "    print(f\"Generating {n_samples} samples with {n_features} features...\")\n",
    "    \n",
    "    # For tabular models (LSTM, simple models)\n",
    "    X_tabular = np.random.randn(n_samples, n_features)\n",
    "    \n",
    "    # Create fire probability based on features\n",
    "    # Higher temperature, lower humidity, higher wind speed increase fire probability\n",
    "    fire_prob = (\n",
    "        0.3 * X_tabular[:, 0] +      # temperature effect\n",
    "        -0.2 * X_tabular[:, 1] +     # humidity effect (negative)\n",
    "        0.15 * X_tabular[:, 2] +     # wind speed effect\n",
    "        0.1 * X_tabular[:, 3] +      # fuel load effect\n",
    "        np.random.randn(n_samples) * 0.1  # noise\n",
    "    )\n",
    "    \n",
    "    # Convert to binary labels\n",
    "    y_tabular = (fire_prob > np.percentile(fire_prob, 90)).astype(int)  # Top 10% as fire\n",
    "    \n",
    "    # For U-Net (image patches)\n",
    "    n_patches = n_samples // 4  # Fewer patches due to memory constraints\n",
    "    X_image = np.random.randn(n_patches, image_size[0], image_size[1], n_features)\n",
    "    \n",
    "    # Create spatial fire patterns\n",
    "    y_image = np.zeros((n_patches, image_size[0], image_size[1], 1))\n",
    "    \n",
    "    for i in range(n_patches):\n",
    "        # Create random fire spots\n",
    "        n_fires = np.random.randint(0, 3)\n",
    "        for _ in range(n_fires):\n",
    "            center_x = np.random.randint(10, image_size[0] - 10)\n",
    "            center_y = np.random.randint(10, image_size[1] - 10)\n",
    "            radius = np.random.randint(3, 8)\n",
    "            \n",
    "            # Create circular fire pattern\n",
    "            y, x = np.ogrid[:image_size[0], :image_size[1]]\n",
    "            mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "            y_image[i, mask, 0] = 1\n",
    "    \n",
    "    print(f\"Generated data shapes:\")\n",
    "    print(f\"  Tabular: X {X_tabular.shape}, y {y_tabular.shape}\")\n",
    "    print(f\"  Image: X {X_image.shape}, y {y_image.shape}\")\n",
    "    print(f\"  Fire percentage (tabular): {np.mean(y_tabular)*100:.1f}%\")\n",
    "    print(f\"  Fire percentage (image): {np.mean(y_image)*100:.1f}%\")\n",
    "    \n",
    "    return X_tabular, y_tabular, X_image, y_image\n",
    "\n",
    "# Generate sample data\n",
    "X_tab, y_tab, X_img, y_img = generate_sample_training_data()\n",
    "\n",
    "# Split data for training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split tabular data\n",
    "X_tab_train, X_tab_test, y_tab_train, y_tab_test = train_test_split(\n",
    "    X_tab, y_tab, test_size=0.2, random_state=42, stratify=y_tab)\n",
    "\n",
    "X_tab_train, X_tab_val, y_tab_train, y_tab_val = train_test_split(\n",
    "    X_tab_train, y_tab_train, test_size=0.2, random_state=42, stratify=y_tab_train)\n",
    "\n",
    "# Split image data\n",
    "X_img_train, X_img_test, y_img_train, y_img_test = train_test_split(\n",
    "    X_img, y_img, test_size=0.2, random_state=42)\n",
    "\n",
    "X_img_train, X_img_val, y_img_train, y_img_val = train_test_split(\n",
    "    X_img_train, y_img_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nData split completed:\")\n",
    "print(f\"  Tabular - Train: {X_tab_train.shape}, Val: {X_tab_val.shape}, Test: {X_tab_test.shape}\")\n",
    "print(f\"  Image - Train: {X_img_train.shape}, Val: {X_img_val.shape}, Test: {X_img_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128d888",
   "metadata": {},
   "source": [
    "## 3. U-Net Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure U-Net model\n",
    "unet_config = config.copy()\n",
    "unet_config.update({\n",
    "    'model_type': 'unet',\n",
    "    'input_shape': [64, 64, 10],  # Match our sample data\n",
    "    'n_classes': 2,\n",
    "    'batch_size': 8,\n",
    "    'epochs': 20,  # Reduced for demo\n",
    "    'learning_rate': 0.001\n",
    "})\n",
    "\n",
    "print(\"Training U-Net Model...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Initialize U-Net model\n",
    "unet_model = UNetFirePredictor(unet_config)\n",
    "\n",
    "# Build model\n",
    "model = unet_model.build_model()\n",
    "print(f\"\\nU-Net model built with input shape: {unet_config['input_shape']}\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79827b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train U-Net model\n",
    "model_save_path = os.path.join(config['paths']['models'], 'unet_demo_model.h5')\n",
    "os.makedirs(config['paths']['models'], exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Train model\n",
    "    history_unet = unet_model.train(\n",
    "        X_img_train, y_img_train,\n",
    "        X_img_val, y_img_val,\n",
    "        model_save_path\n",
    "    )\n",
    "    \n",
    "    print(\"\\nU-Net training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during U-Net training: {e}\")\n",
    "    history_unet = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045388f",
   "metadata": {},
   "source": [
    "## 4. LSTM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LSTM model\n",
    "lstm_config = config.copy()\n",
    "lstm_config.update({\n",
    "    'model_type': 'lstm',\n",
    "    'sequence_length': 7,\n",
    "    'n_features': 10,\n",
    "    'hidden_size': 64,  # Reduced for demo\n",
    "    'n_layers': 2,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 20,  # Reduced for demo\n",
    "    'learning_rate': 0.001\n",
    "})\n",
    "\n",
    "print(\"Training LSTM Model...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Initialize LSTM model\n",
    "lstm_model = LSTMFirePredictor(lstm_config)\n",
    "\n",
    "# Prepare sequential data for LSTM\n",
    "print(\"Preparing sequential data for LSTM...\")\n",
    "\n",
    "def create_sequences(X, y, sequence_length=7):\n",
    "    \"\"\"Create sequences for LSTM training.\"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for i in range(sequence_length, len(X)):\n",
    "        X_seq.append(X[i-sequence_length:i])\n",
    "        y_seq.append(y[i])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create sequences\n",
    "X_lstm_train, y_lstm_train = create_sequences(X_tab_train, y_tab_train, lstm_config['sequence_length'])\n",
    "X_lstm_val, y_lstm_val = create_sequences(X_tab_val, y_tab_val, lstm_config['sequence_length'])\n",
    "X_lstm_test, y_lstm_test = create_sequences(X_tab_test, y_tab_test, lstm_config['sequence_length'])\n",
    "\n",
    "print(f\"LSTM sequences created:\")\n",
    "print(f\"  Train: {X_lstm_train.shape}\")\n",
    "print(f\"  Val: {X_lstm_val.shape}\")\n",
    "print(f\"  Test: {X_lstm_test.shape}\")\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model_tf = lstm_model.build_model()\n",
    "print(f\"\\nLSTM model built\")\n",
    "print(f\"Total parameters: {lstm_model_tf.count_params():,}\")\n",
    "\n",
    "# Display model summary\n",
    "lstm_model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24afdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM model\n",
    "lstm_model_save_path = os.path.join(config['paths']['models'], 'lstm_demo_model.h5')\n",
    "\n",
    "try:\n",
    "    # Train model\n",
    "    history_lstm = lstm_model.train(\n",
    "        X_lstm_train, y_lstm_train,\n",
    "        X_lstm_val, y_lstm_val,\n",
    "        lstm_model_save_path\n",
    "    )\n",
    "    \n",
    "    print(\"\\nLSTM training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during LSTM training: {e}\")\n",
    "    history_lstm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ba4d7",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# Evaluate U-Net model\n",
    "if history_unet is not None:\n",
    "    print(\"Evaluating U-Net Model...\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_unet_proba = unet_model.predict(X_img_test)\n",
    "    y_pred_unet = (y_pred_unet_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Flatten for evaluation\n",
    "    y_true_unet_flat = y_img_test.flatten()\n",
    "    y_pred_unet_flat = y_pred_unet.flatten()\n",
    "    y_pred_unet_proba_flat = y_pred_unet_proba.flatten()\n",
    "    \n",
    "    # Evaluate\n",
    "    unet_metrics = evaluator.evaluate_model(\n",
    "        y_true_unet_flat, y_pred_unet_flat, y_pred_unet_proba_flat,\n",
    "        save_path=os.path.join(config['output_dirs']['metrics'], 'unet_metrics.json')\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    evaluator.plot_training_history(\n",
    "        history_unet, \n",
    "        save_path=os.path.join(config['output_dirs']['visualizations'], 'unet_training_history.png')\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    evaluator.plot_confusion_matrix(\n",
    "        y_true_unet_flat, y_pred_unet_flat,\n",
    "        save_path=os.path.join(config['output_dirs']['visualizations'], 'unet_confusion_matrix.png')\n",
    "    )\n",
    "\n",
    "# Evaluate LSTM model\n",
    "if history_lstm is not None:\n",
    "    print(\"\\nEvaluating LSTM Model...\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_lstm_proba = lstm_model.model.predict(X_lstm_test)\n",
    "    y_pred_lstm = (y_pred_lstm_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Evaluate\n",
    "    lstm_metrics = evaluator.evaluate_model(\n",
    "        y_lstm_test, y_pred_lstm.flatten(), y_pred_lstm_proba.flatten(),\n",
    "        save_path=os.path.join(config['output_dirs']['metrics'], 'lstm_metrics.json')\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    evaluator.plot_training_history(\n",
    "        history_lstm,\n",
    "        save_path=os.path.join(config['output_dirs']['visualizations'], 'lstm_training_history.png')\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    evaluator.plot_confusion_matrix(\n",
    "        y_lstm_test, y_pred_lstm.flatten(),\n",
    "        save_path=os.path.join(config['output_dirs']['visualizations'], 'lstm_confusion_matrix.png')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8db1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "if history_unet is not None and history_lstm is not None:\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC'],\n",
    "        'U-Net': [\n",
    "            unet_metrics['accuracy'],\n",
    "            unet_metrics['precision'],\n",
    "            unet_metrics['recall'],\n",
    "            unet_metrics['f1_score'],\n",
    "            unet_metrics.get('roc_auc', 0)\n",
    "        ],\n",
    "        'LSTM': [\n",
    "            lstm_metrics['accuracy'],\n",
    "            lstm_metrics['precision'],\n",
    "            lstm_metrics['recall'],\n",
    "            lstm_metrics['f1_score'],\n",
    "            lstm_metrics.get('roc_auc', 0)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    import pandas as pd\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.round(4))\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    x = np.arange(len(comparison_data['Metric']))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, comparison_data['U-Net'], width, label='U-Net', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, comparison_data['LSTM'], width, label='LSTM', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(comparison_data['Metric'])\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    def add_value_labels(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    add_value_labels(bars1)\n",
    "    add_value_labels(bars2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config['output_dirs']['visualizations'], 'model_comparison.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe36ec4c",
   "metadata": {},
   "source": [
    "## 6. Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize U-Net predictions\n",
    "if history_unet is not None:\n",
    "    print(\"Visualizing U-Net Predictions...\")\n",
    "    \n",
    "    # Select some test samples for visualization\n",
    "    n_samples = min(4, len(X_img_test))\n",
    "    sample_indices = np.random.choice(len(X_img_test), n_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4*n_samples))\n",
    "    if n_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # Input features (show first channel)\n",
    "        axes[i, 0].imshow(X_img_test[idx, :, :, 0], cmap='viridis')\n",
    "        axes[i, 0].set_title(f'Input Features (Sample {idx})')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # True label\n",
    "        axes[i, 1].imshow(y_img_test[idx, :, :, 0], cmap='Reds', vmin=0, vmax=1)\n",
    "        axes[i, 1].set_title('True Fire Map')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Predicted probability\n",
    "        pred_prob = y_pred_unet_proba[idx, :, :, 0]\n",
    "        axes[i, 2].imshow(pred_prob, cmap='Reds', vmin=0, vmax=1)\n",
    "        axes[i, 2].set_title('Predicted Probability')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Predicted binary\n",
    "        pred_binary = y_pred_unet[idx, :, :, 0]\n",
    "        axes[i, 3].imshow(pred_binary, cmap='Reds', vmin=0, vmax=1)\n",
    "        axes[i, 3].set_title('Predicted Fire Map')\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config['output_dirs']['visualizations'], 'unet_predictions.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize LSTM predictions\n",
    "if history_lstm is not None:\n",
    "    print(\"\\nVisualizing LSTM Predictions...\")\n",
    "    \n",
    "    # Plot prediction vs actual for time series\n",
    "    n_plot = min(100, len(y_lstm_test))\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(y_lstm_test[:n_plot], 'o-', label='Actual', alpha=0.7, markersize=4)\n",
    "    plt.plot(y_pred_lstm_proba[:n_plot], 's-', label='Predicted Probability', alpha=0.7, markersize=3)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Fire Occurrence')\n",
    "    plt.title('LSTM Predictions vs Actual')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(y_lstm_test, y_pred_lstm_proba, alpha=0.6)\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Perfect Prediction')\n",
    "    plt.xlabel('Actual Fire Occurrence')\n",
    "    plt.ylabel('Predicted Probability')\n",
    "    plt.title('Predicted vs Actual Scatter Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config['output_dirs']['visualizations'], 'lstm_predictions.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fda8f9",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated the training and evaluation of both U-Net and LSTM models for forest fire prediction:\n",
    "\n",
    "### Key Accomplishments:\n",
    "1. **Model Setup**: Configured and built both U-Net and LSTM architectures\n",
    "2. **Training**: Trained models on sample data with proper validation\n",
    "3. **Evaluation**: Comprehensive performance assessment with multiple metrics\n",
    "4. **Visualization**: Created plots for training history, confusion matrices, and predictions\n",
    "5. **Comparison**: Side-by-side comparison of model performance\n",
    "\n",
    "### Model Characteristics:\n",
    "- **U-Net**: Better for spatial fire patterns and pixel-level predictions\n",
    "- **LSTM**: Better for temporal patterns and time-series prediction\n",
    "\n",
    "### Next Steps:\n",
    "1. **Real Data**: Replace sample data with actual environmental and fire history data\n",
    "2. **Hyperparameter Tuning**: Optimize model parameters for better performance\n",
    "3. **Ensemble Methods**: Combine both models for improved predictions\n",
    "4. **Feature Engineering**: Add more relevant environmental features\n",
    "5. **Cross-Validation**: Implement more robust validation strategies\n",
    "\n",
    "### Files Generated:\n",
    "- Model weights: `models/unet_demo_model.h5`, `models/lstm_demo_model.h5`\n",
    "- Evaluation metrics: `data/outputs/metrics/`\n",
    "- Visualizations: `data/outputs/visualizations/`\n",
    "\n",
    "**Note**: This demonstration uses synthetic data. For production use, ensure you have:\n",
    "- High-quality environmental data (weather, terrain, vegetation)\n",
    "- Accurate historical fire occurrence data\n",
    "- Proper data preprocessing and alignment\n",
    "- Sufficient computational resources for larger datasets"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
