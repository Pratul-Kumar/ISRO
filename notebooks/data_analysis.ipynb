{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe54267",
   "metadata": {},
   "source": [
    "# Forest Fire Prediction and Simulation - Data Analysis\n",
    "\n",
    "This notebook provides exploratory data analysis and visualization tools for the forest fire prediction project.\n",
    "\n",
    "## Contents\n",
    "1. Data Loading and Inspection\n",
    "2. Environmental Data Analysis\n",
    "3. Historical Fire Pattern Analysis\n",
    "4. Correlation Analysis\n",
    "5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio.plot import show\n",
    "import folium\n",
    "from folium import plugins\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e2a6c",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raster_data(file_path, band=1):\n",
    "    \"\"\"Load raster data and return array with metadata.\"\"\"\n",
    "    try:\n",
    "        with rasterio.open(file_path) as src:\n",
    "            data = src.read(band)\n",
    "            profile = src.profile\n",
    "            bounds = src.bounds\n",
    "            crs = src.crs\n",
    "            \n",
    "        return {\n",
    "            'data': data,\n",
    "            'profile': profile,\n",
    "            'bounds': bounds,\n",
    "            'crs': crs,\n",
    "            'shape': data.shape,\n",
    "            'dtype': data.dtype\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def inspect_raster(raster_info, name):\n",
    "    \"\"\"Print raster inspection summary.\"\"\"\n",
    "    if raster_info is None:\n",
    "        print(f\"{name}: Failed to load\")\n",
    "        return\n",
    "        \n",
    "    data = raster_info['data']\n",
    "    print(f\"\\n{name} Raster Information:\")\n",
    "    print(f\"  Shape: {raster_info['shape']}\")\n",
    "    print(f\"  Data type: {raster_info['dtype']}\")\n",
    "    print(f\"  CRS: {raster_info['crs']}\")\n",
    "    print(f\"  Bounds: {raster_info['bounds']}\")\n",
    "    print(f\"  Min value: {np.nanmin(data):.4f}\")\n",
    "    print(f\"  Max value: {np.nanmax(data):.4f}\")\n",
    "    print(f\"  Mean value: {np.nanmean(data):.4f}\")\n",
    "    print(f\"  NoData pixels: {np.sum(np.isnan(data))} ({np.sum(np.isnan(data))/data.size*100:.2f}%)\")\n",
    "\n",
    "# Example usage (modify paths to your actual data)\n",
    "data_dir = \"../data/raw\"\n",
    "\n",
    "# Define sample data files (replace with your actual files)\n",
    "sample_files = {\n",
    "    \"Temperature\": os.path.join(data_dir, \"temperature.tif\"),\n",
    "    \"Humidity\": os.path.join(data_dir, \"humidity.tif\"),\n",
    "    \"DEM\": os.path.join(data_dir, \"dem.tif\"),\n",
    "    \"Land Cover\": os.path.join(data_dir, \"landcover.tif\")\n",
    "}\n",
    "\n",
    "# Load and inspect data (only if files exist)\n",
    "raster_data = {}\n",
    "for name, file_path in sample_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        raster_data[name] = load_raster_data(file_path)\n",
    "        inspect_raster(raster_data[name], name)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        \n",
    "print(f\"\\nLoaded {len(raster_data)} raster datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34a5a4",
   "metadata": {},
   "source": [
    "## 2. Environmental Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1becb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster_data(raster_info, title, cmap='viridis', figsize=(10, 8)):\n",
    "    \"\"\"Plot raster data with statistics.\"\"\"\n",
    "    if raster_info is None:\n",
    "        print(f\"Cannot plot {title}: No data loaded\")\n",
    "        return\n",
    "        \n",
    "    data = raster_info['data']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # Raster plot\n",
    "    im = axes[0].imshow(data, cmap=cmap, aspect='equal')\n",
    "    axes[0].set_title(f'{title} - Spatial Distribution')\n",
    "    axes[0].set_xlabel('X (pixels)')\n",
    "    axes[0].set_ylabel('Y (pixels)')\n",
    "    plt.colorbar(im, ax=axes[0])\n",
    "    \n",
    "    # Histogram\n",
    "    valid_data = data[~np.isnan(data)]\n",
    "    axes[1].hist(valid_data, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_title(f'{title} - Value Distribution')\n",
    "    axes[1].set_xlabel('Value')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].axvline(np.mean(valid_data), color='red', linestyle='--', label=f'Mean: {np.mean(valid_data):.2f}')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot loaded raster data\n",
    "cmaps = {\n",
    "    \"Temperature\": \"RdYlBu_r\",\n",
    "    \"Humidity\": \"Blues\",\n",
    "    \"DEM\": \"terrain\",\n",
    "    \"Land Cover\": \"tab20\"\n",
    "}\n",
    "\n",
    "for name, data in raster_data.items():\n",
    "    cmap = cmaps.get(name, 'viridis')\n",
    "    plot_raster_data(data, name, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10183899",
   "metadata": {},
   "source": [
    "## 3. Generate Sample Data for Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f380b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data(shape=(500, 500)):\n",
    "    \"\"\"Generate sample environmental data for demonstration.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    y, x = np.ogrid[:shape[0], :shape[1]]\n",
    "    \n",
    "    # Temperature (decreases with elevation)\n",
    "    elevation = 100 + 1500 * np.sin(y/100) * np.cos(x/150) + 200 * np.random.random(shape)\n",
    "    temperature = 35 - elevation/100 + 5 * np.random.random(shape)\n",
    "    \n",
    "    # Humidity (varies with location)\n",
    "    humidity = 40 + 30 * np.sin(y/80) + 10 * np.random.random(shape)\n",
    "    humidity = np.clip(humidity, 0, 100)\n",
    "    \n",
    "    # Wind speed\n",
    "    wind_speed = 5 + 10 * np.random.random(shape)\n",
    "    \n",
    "    # Fuel load (land cover based)\n",
    "    fuel_load = np.random.choice([0.1, 0.3, 0.6, 0.8, 0.9], size=shape, p=[0.1, 0.2, 0.3, 0.3, 0.1])\n",
    "    \n",
    "    # Historical fires (sparse)\n",
    "    fire_history = np.random.choice([0, 1], size=shape, p=[0.98, 0.02])\n",
    "    \n",
    "    return {\n",
    "        'temperature': temperature,\n",
    "        'humidity': humidity,\n",
    "        'elevation': elevation,\n",
    "        'wind_speed': wind_speed,\n",
    "        'fuel_load': fuel_load,\n",
    "        'fire_history': fire_history\n",
    "    }\n",
    "\n",
    "# Generate sample data\n",
    "sample_data = generate_sample_data()\n",
    "\n",
    "print(\"Generated sample environmental data:\")\n",
    "for name, data in sample_data.items():\n",
    "    print(f\"  {name}: shape {data.shape}, range [{data.min():.2f}, {data.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028d045",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlations(data_dict, target_var='fire_history'):\n",
    "    \"\"\"Analyze correlations between environmental variables and fire occurrence.\"\"\"\n",
    "    \n",
    "    # Flatten arrays and create DataFrame\n",
    "    df_data = {}\n",
    "    for name, data in data_dict.items():\n",
    "        df_data[name] = data.flatten()\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    # Remove NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df.corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0,\n",
    "                square=True, fmt='.3f', cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    plt.title('Environmental Variables Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print correlations with target variable\n",
    "    if target_var in df.columns:\n",
    "        target_corr = corr_matrix[target_var].drop(target_var).sort_values(key=abs, ascending=False)\n",
    "        print(f\"\\nCorrelations with {target_var}:\")\n",
    "        print(\"-\" * 40)\n",
    "        for var, corr in target_corr.items():\n",
    "            print(f\"{var:15s}: {corr:6.3f}\")\n",
    "    \n",
    "    return df, corr_matrix\n",
    "\n",
    "# Analyze sample data correlations\n",
    "df, corr_matrix = analyze_correlations(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd010e3",
   "metadata": {},
   "source": [
    "## 5. Fire Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_fire_risk_factors(df):\n",
    "    \"\"\"Analyze environmental conditions in fire vs non-fire areas.\"\"\"\n",
    "    \n",
    "    if 'fire_history' not in df.columns:\n",
    "        print(\"No fire history data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Separate fire and non-fire areas\n",
    "    fire_areas = df[df['fire_history'] == 1]\n",
    "    no_fire_areas = df[df['fire_history'] == 0]\n",
    "    \n",
    "    print(f\"Fire areas: {len(fire_areas)} pixels ({len(fire_areas)/len(df)*100:.2f}%)\")\n",
    "    print(f\"No-fire areas: {len(no_fire_areas)} pixels ({len(no_fire_areas)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Environmental variables to analyze\n",
    "    env_vars = ['temperature', 'humidity', 'elevation', 'wind_speed', 'fuel_load']\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, var in enumerate(env_vars):\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        # Box plot comparison\n",
    "        data_to_plot = [no_fire_areas[var], fire_areas[var]]\n",
    "        axes[i].boxplot(data_to_plot, labels=['No Fire', 'Fire'])\n",
    "        axes[i].set_title(f'{var.title()} Distribution')\n",
    "        axes[i].set_ylabel(var.title())\n",
    "        \n",
    "        # Add mean lines\n",
    "        axes[i].axhline(no_fire_areas[var].mean(), color='blue', linestyle='--', alpha=0.7)\n",
    "        axes[i].axhline(fire_areas[var].mean(), color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Remove empty subplot\n",
    "    if len(env_vars) < len(axes):\n",
    "        axes[-1].remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical comparison\n",
    "    from scipy import stats\n",
    "    \n",
    "    print(\"\\nStatistical Comparison (Fire vs No-Fire):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Variable':<15} {'Fire Mean':<12} {'No-Fire Mean':<15} {'P-value':<10} {'Significant':<12}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for var in env_vars:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        fire_mean = fire_areas[var].mean()\n",
    "        no_fire_mean = no_fire_areas[var].mean()\n",
    "        \n",
    "        # T-test\n",
    "        statistic, p_value = stats.ttest_ind(fire_areas[var], no_fire_areas[var])\n",
    "        significant = \"Yes\" if p_value < 0.05 else \"No\"\n",
    "        \n",
    "        print(f\"{var:<15} {fire_mean:<12.3f} {no_fire_mean:<15.3f} {p_value:<10.3e} {significant:<12}\")\n",
    "\n",
    "# Analyze fire risk factors\n",
    "analyze_fire_risk_factors(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcaef1a",
   "metadata": {},
   "source": [
    "## 6. Interactive Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_map(data_dict, center_lat=40.0, center_lon=-120.0):\n",
    "    \"\"\"Create interactive map with environmental layers.\"\"\"\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=10,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Add layer control\n",
    "    folium.plugins.Fullscreen().add_to(m)\n",
    "    \n",
    "    # Note: In a real scenario, you would add raster overlays here\n",
    "    # For demonstration, we'll add sample markers\n",
    "    \n",
    "    # Add sample fire locations\n",
    "    if 'fire_history' in data_dict:\n",
    "        fire_data = data_dict['fire_history']\n",
    "        fire_locations = np.where(fire_data == 1)\n",
    "        \n",
    "        # Sample some fire locations to avoid overcrowding\n",
    "        n_samples = min(100, len(fire_locations[0]))\n",
    "        indices = np.random.choice(len(fire_locations[0]), n_samples, replace=False)\n",
    "        \n",
    "        for i in indices:\n",
    "            lat = center_lat + (fire_locations[0][i] - fire_data.shape[0]/2) * 0.001\n",
    "            lon = center_lon + (fire_locations[1][i] - fire_data.shape[1]/2) * 0.001\n",
    "            \n",
    "            folium.CircleMarker(\n",
    "                location=[lat, lon],\n",
    "                radius=3,\n",
    "                popup='Historical Fire',\n",
    "                color='red',\n",
    "                fillColor='red',\n",
    "                fillOpacity=0.7\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 10px; right: 10px; width: 200px; height: 90px; \n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\">\n",
    "    <h4>Legend</h4>\n",
    "    <i class=\"fa fa-circle\" style=\"color:red\"></i> Historical Fire Locations<br>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Create interactive map\n",
    "interactive_map = create_interactive_map(sample_data)\n",
    "interactive_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74994e7",
   "metadata": {},
   "source": [
    "## 7. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_data_quality(data_dict):\n",
    "    \"\"\"Assess data quality and completeness.\"\"\"\n",
    "    \n",
    "    print(\"DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    quality_report = {}\n",
    "    \n",
    "    for name, data in data_dict.items():\n",
    "        total_pixels = data.size\n",
    "        valid_pixels = np.sum(~np.isnan(data))\n",
    "        missing_pixels = total_pixels - valid_pixels\n",
    "        missing_percentage = (missing_pixels / total_pixels) * 100\n",
    "        \n",
    "        # Check for outliers (values beyond 3 standard deviations)\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        if len(valid_data) > 0:\n",
    "            mean_val = np.mean(valid_data)\n",
    "            std_val = np.std(valid_data)\n",
    "            outliers = np.sum(np.abs(valid_data - mean_val) > 3 * std_val)\n",
    "            outlier_percentage = (outliers / len(valid_data)) * 100\n",
    "        else:\n",
    "            outliers = 0\n",
    "            outlier_percentage = 0\n",
    "        \n",
    "        quality_report[name] = {\n",
    "            'total_pixels': total_pixels,\n",
    "            'valid_pixels': valid_pixels,\n",
    "            'missing_pixels': missing_pixels,\n",
    "            'missing_percentage': missing_percentage,\n",
    "            'outliers': outliers,\n",
    "            'outlier_percentage': outlier_percentage\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        print(f\"  Total pixels: {total_pixels:,}\")\n",
    "        print(f\"  Valid pixels: {valid_pixels:,} ({100-missing_percentage:.2f}%)\")\n",
    "        print(f\"  Missing pixels: {missing_pixels:,} ({missing_percentage:.2f}%)\")\n",
    "        print(f\"  Outliers (>3σ): {outliers:,} ({outlier_percentage:.2f}%)\")\n",
    "        \n",
    "        # Quality assessment\n",
    "        if missing_percentage < 5:\n",
    "            quality = \"Excellent\"\n",
    "        elif missing_percentage < 15:\n",
    "            quality = \"Good\"\n",
    "        elif missing_percentage < 30:\n",
    "            quality = \"Fair\"\n",
    "        else:\n",
    "            quality = \"Poor\"\n",
    "        \n",
    "        print(f\"  Data Quality: {quality}\")\n",
    "    \n",
    "    # Summary plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Missing data percentage\n",
    "    names = list(quality_report.keys())\n",
    "    missing_pcts = [quality_report[name]['missing_percentage'] for name in names]\n",
    "    \n",
    "    bars1 = ax1.bar(names, missing_pcts, color='lightcoral')\n",
    "    ax1.set_title('Missing Data Percentage by Variable')\n",
    "    ax1.set_ylabel('Missing Data (%)')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, pct in zip(bars1, missing_pcts):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f'{pct:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Outlier percentage\n",
    "    outlier_pcts = [quality_report[name]['outlier_percentage'] for name in names]\n",
    "    \n",
    "    bars2 = ax2.bar(names, outlier_pcts, color='lightskyblue')\n",
    "    ax2.set_title('Outlier Percentage by Variable')\n",
    "    ax2.set_ylabel('Outliers (%)')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, pct in zip(bars2, outlier_pcts):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{pct:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Assess data quality\n",
    "quality_report = assess_data_quality(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40b900",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive analysis tools for the forest fire prediction project:\n",
    "\n",
    "1. **Data Loading and Inspection**: Functions to load and examine raster datasets\n",
    "2. **Visualization**: Tools for plotting environmental data and distributions\n",
    "3. **Correlation Analysis**: Methods to identify relationships between variables\n",
    "4. **Fire Risk Analysis**: Comparison of environmental conditions in fire vs non-fire areas\n",
    "5. **Interactive Mapping**: Folium-based maps for spatial visualization\n",
    "6. **Data Quality Assessment**: Evaluation of data completeness and quality\n",
    "\n",
    "**Next Steps:**\n",
    "- Replace sample data with your actual environmental datasets\n",
    "- Modify file paths in the configuration\n",
    "- Run the main pipeline using the insights gained from this analysis\n",
    "\n",
    "**Note:** This notebook uses sample data for demonstration. Update the file paths to use your actual data files."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
